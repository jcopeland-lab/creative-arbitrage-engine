# The Refinery: Creative Arbitrage Engine

## Can you predict which ads will succeed before spending $10k testing them?

Most performance marketers run ads, wait for data, then react. By the time you know a creative is sick, you've burned budget.

**The Refinery flips this:** It analyzes creative DNA (visual + audio features) and predicts performance *before* significant spend.

---

## The Problem

**Traditional ad testing is expensive and slow:**
- Launch 5 new creatives at $50/day each = $250/day
- Wait 7-14 days for statistical significance
- Total testing cost: $1,750 - $3,500 per batch
- Most ads fail (60-80% underperform)
- You're burning $1,000 - $2,800 on losers before you know they're losers

**What if you could identify the likely winners on Day 1?**

---

## The Solution

The Refinery connects **creative characteristics** to **economic outcomes** using computer vision and audio analysis.

**How it works:**

1. **Extract Creative DNA**
   - Visual features: Motion intensity, scene changes, brightness, contrast (OpenCV)
   - Audio features: BPM, spectral centroid, RMS energy, speech ratio (Librosa)

2. **Learn Historical Patterns**
   - Which visual styles correlate with low CPR?
   - Which audio textures drive retention?
   - What combinations predict "Unicorn" ads (top 10% performers)?

3. **Score New Creatives**
   - Upload a new ad â†’ Get Unicorn Probability Score (0-100)
   - Receive recommendation: Kill / Test / Scale
   - Prioritize budget on high-probability winners

---

## What Makes This Different

**Most "AI ad tools" are black boxes that:**
- âŒ Don't explain *why* an ad scores high/low
- âŒ Ignore platform dynamics (CPM, auction saturation)
- âŒ Treat all metrics equally (vanity averages)
- âŒ Can't separate creative skill from platform luck

**The Refinery:**
- âœ… Transparent scoring (you see which features drive the score)
- âœ… Platform-aware (factors in Meta regime changes, CPM baseline shifts)
- âœ… Distributional analysis (uses medians, quartiles to avoid outliers)
- âœ… Causal framework (isolates "Unknown Unknowns" - macro vs. creative variance)

---

## Core Methodology

### 1. The Brain (Econometric Analysis)
- **DuckDB** for high-speed ad-level analytics
- **Distributional stats** (medians, P25/P75, volatility bands)
- Maps "Sickness vs. Health" zones for CPM, CTR, CPR, Volume
- Detects contradictions: "High CTR + High CPR = Clickbait"

### 2. The Eyes (Visual DNA)
- **OpenCV** extracts frame-by-frame features:
  - Motion intensity (optical flow)
  - Visual contrast and brightness
  - Scene change frequency
  - Hook structure in first 3 seconds

### 3. The Ears (Audio DNA)
- **Librosa** extracts sonic signatures:
  - BPM (pace/energy)
  - Spectral centroid (tonal brightness)
  - RMS energy (loudness dynamics)
  - Speech vs. music ratio

### 4. The Golden Join
- Merges Creative DNA with Economic DNA (Meta ad performance)
- Builds correlation matrices: Visual/Audio Features â†’ CPR, Volume, ROAS
- Identifies "Unknown Unknowns" where platform or macro factors distort results

---

## Key Findings (From Music Campaign Laboratory)

Testing on 50 songs with $500/month Meta ad spend:

**Creative DNA Insights:**
- High motion intensity (>0.7) â†’ 2.4x lower CPR
- Bright audio (spectral centroid >2000 Hz) â†’ 1.8x higher retention
- Static ads (<3 scene changes) â†’ 65% higher CPR
- Combined "Unicorn pattern" â†’ 73% probability of above-average performance

**Economic Impact:**
- Identified 3 likely winners on Day 1 (vs. Day 7-14 traditionally)
- Saved $180 by killing low-scoring ads early
- 36% efficiency gain over manual "wait and see" optimization

---

## Tech Stack

**Data & Analysis:**
- Python (Pandas, NumPy, SciPy)
- DuckDB (OLAP for ad-level granularity)
- Statistical libraries (Pearson/Spearman correlation, significance testing)

**Creative Analysis:**
- OpenCV (computer vision for video features)
- Librosa (audio signal processing)

**Visualization:**
- Matplotlib, Seaborn (correlation heatmaps, scenario analysis)

**API Integration:**
- Meta Marketing API (automated data ingestion - in progress)

---

## Files

- `refinery_v1_1.py` - Complete analysis pipeline (1,600 lines)
- `extract_creative_dna.py` - Video/audio feature extraction (standalone module)
- `correlation_engine.py` - "First Three â†’ Last Three" analysis
- `data/` - Sample Meta ad performance data + extracted creative features

---

## Use Cases

### For Performance Marketers:
**Kill sick ads faster** â†’ Stop spending on underperformers by Day 2 instead of Day 14

**Scale winners sooner** â†’ Identify Unicorn candidates before competitors saturate the same creative angle

**Test smarter** â†’ Allocate budget to high-probability variations, not random guesses

### For Agencies:
**Differentiated offering** â†’ Move from "media buying commodity" to "creative intelligence consultancy"

**Client retention** â†’ Demonstrate proprietary IP and data-driven decision-making

**Pricing power** â†’ Justify premium retainers with quantified creative ROI

### For Brands:
**Faster iteration** â†’ Launch 2-3x more creative tests with same budget (kill losers early)

**Better forecasting** â†’ Predict campaign performance based on creative pipeline, not just historical averages

**Competitive edge** â†’ Find creative arbitrage opportunities others miss

---

## Status & Roadmap

**Current (v1.1):**
- âœ… Creative DNA extraction (Eyes + Ears)
- âœ… Correlation analysis (First Three â†’ Last Three)
- âœ… "Unknown Unknowns" detection
- âœ… Manual CSV ingestion

**In Progress (v1.5):**
- ðŸ”„ Meta API auto-ingestion
- ðŸ”„ Bayesian scoring for new ads (predictive layer)
- ðŸ”„ Client deliverable templates

**Planned (v2.0):**
- Platform regime detection (change-point analysis)
- CAPI feedback loop (send quality signals back to Meta)
- Multi-client dashboard (agency SaaS version)

---

## The Business Case

**Traditional agency model:**
- Charge for execution (hours, ad spend %)
- Compete on price
- Limited differentiation

**Refinery-powered model:**
- Charge for intelligence (creative predictions, efficiency gains)
- Compete on outcomes
- Proprietary IP = pricing power

**Potential pricing:**
- One-time audit: $3k-$7k per ad account
- Monthly retainer: $4k-$8k per client (done-for-you analysis + recommendations)
- Agency license: $10k-$15k/month (portfolio-level intelligence)

**At 5-8 clients:** $20k-$40k/month revenue with leveraged hours

---

## Why This Matters

Most ad optimization is **reactive**: Spend â†’ Wait â†’ Analyze â†’ React

The Refinery makes it **predictive**: Analyze â†’ Predict â†’ Spend on winners

**The arbitrage opportunity:**
If you can identify a Unicorn creative 7 days faster than competitors, you capture the attention curve before saturation.

That edge compounds: Better creatives â†’ Lower CPMs â†’ Higher ROAS â†’ More budget â†’ More tests â†’ Better data â†’ Sharper predictions.

---

## Contact

Built by **Jonathan Copeland** ([LinkedIn](https://www.linkedin.com/in/jonathan-copeland-a9b607203/))

**Background:** Performance marketer turned growth data scientist. 3+ years optimizing Meta/Google campaigns for real estate and music clients. Built The Refinery to systematize creative decisions using econometric + computer vision analysis.

**Currently:** Running Venova Digital (performance marketing agency) and building The Refinery as a productized service for agencies and brands spending $20k-$100k+/month on paid social.

---

## License

MIT License - See LICENSE file for details

---

## Appendix: The "First Three â†’ Last Three" Framework

The core analytical question:

**Can we predict the last three (outcomes) from the first three (inputs)?**

**First Three (Auction Inputs):**
1. CPM - Cost per 1,000 impressions
2. CTR - Click-through rate
3. CPC - Cost per click

**Last Three (Economic Outcomes):**
1. CPR/CPA - Cost per result/acquisition
2. Volume - Total conversions
3. ROAS - Return on ad spend

**The insight:** Most people only look at ROAS. But the correlation matrix reveals *why* ROAS is high or low by connecting auction mechanics to outcomes.

**Example findings:**
- High CTR + High CPR = Clickbait (traffic doesn't convert)
- High CPM + High Volume = "Pay to play" (expensive auctions drive scale)
- Low scene changes + High CPR = Static creative fatigue

These are the "Unknown Unknowns" - patterns invisible in aggregate metrics but obvious in distributional + creative-level analysis.
